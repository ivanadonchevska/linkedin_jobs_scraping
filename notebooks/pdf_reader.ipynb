{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Extract text from PDF files with PyPDF2 and Pdfminer\n",
    "\n",
    "    PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKILLS  \n",
      " \n",
      "● Advanced proficiency in SQL, Java, P ython and Apache Spark.  \n",
      "● Machine learning and Data Science: Scikit -learn and TensorFlow.  \n",
      "● Experience with data visualization and reporting tools such as Tableau  and Flask . \n",
      "● Strong analytical and problem -solving skills .\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "pdfFileObj = open('../resume/resume_skills_example.pdf', 'rb')\n",
    "\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "\n",
    "extracted_text = \"\"\n",
    "for page in pdfReader.pages:\n",
    "    extracted_text += page.extract_text().strip()  \n",
    "\n",
    "print(extracted_text)\n",
    "\n",
    "pdfFileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is a whitespace issue in the extract_text() method of PyPDF2.\n",
    "\n",
    "Examples: P ython, Scikit -learn.\n",
    "\n",
    "To solve this problem, we can use pdfminer which is more accurate in text extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "def pdf_miner(file_path):\n",
    "    output_string = StringIO()\n",
    "    with open(file_path, \"rb\") as in_file:\n",
    "        parser = PDFParser(in_file)\n",
    "        doc = PDFDocument(parser)\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        for page in PDFPage.create_pages(doc):\n",
    "            interpreter.process_page(page)\n",
    "\n",
    "    resume_txt = output_string.getvalue()  # str type\n",
    "    return resume_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKILLS \n",
      "\n",
      "●  Advanced proficiency in SQL, Java, Python and Apache Spark. \n",
      "●  Machine learning and Data Science: Scikit-learn and TensorFlow. \n",
      "●  Experience with data visualization and reporting tools such as Tableau and Flask. \n",
      "●  Strong analytical and problem-solving skills. \n",
      "\n",
      " \n",
      "\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "output_string = StringIO()\n",
    "\n",
    "with open('../resume/resume_skills_example.pdf', 'rb') as in_file:\n",
    "    parser = PDFParser(in_file)\n",
    "    doc = PDFDocument(parser)\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    for page in PDFPage.create_pages(doc):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "extracted_text = output_string.getvalue()\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Extracting skills using NLP techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfminer.six > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql\n",
      "c\n",
      "security\n",
      "software\n",
      "testing\n",
      "mobile\n",
      "net\n",
      "php\n",
      "server\n",
      "specification\n",
      "support\n",
      "business\n",
      "design\n",
      "workflow\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def load_skills_from_jsonl(file_path):\n",
    "    skills_set = set()\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            skill_entry = json.loads(line.strip())\n",
    "            # Extract skill from \"pattern\" key\n",
    "            skill_name = \" \".join([token[\"LOWER\"] for token in skill_entry[\"pattern\"]])\n",
    "            skills_set.add(skill_name)\n",
    "    return skills_set\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    return extract_text(file_path)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Applies NLP preprocessing: lowercasing, punctuation removal, lemmatization, stopword removal.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Tokenization, lemmatization, and stopword removal\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    \n",
    "    return set(tokens)\n",
    "\n",
    "\n",
    "def extract_skills_from_resume(file_path, predefined_skills):\n",
    "    raw_text = extract_text_from_pdf(file_path)\n",
    "    processed_tokens = preprocess_text(raw_text)\n",
    "    \n",
    "    matched_skills = processed_tokens.intersection(predefined_skills)\n",
    "    return matched_skills\n",
    "\n",
    "\n",
    "predefined_skills = load_skills_from_jsonl(\"../data/skill_patterns.jsonl\")\n",
    "matched_skills = extract_skills_from_resume(\"../resume/Junior_software_developer.pdf\", predefined_skills)\n",
    "\n",
    "# print(\"Extracted Skills:\", matched_skills)\n",
    "for skill in matched_skills:\n",
    "    print(skill)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
